#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GeoTIFF Processor
GeoTIFFãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€æŒ‡å®šåº§æ¨™å‘¨è¾ºã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºãƒ»è§£æž

å¯¾å¿œå½¢å¼:
- GeoTIFF (.tif, .tiff)
- HDF5 (.h5) - GCOM-C/SGLIå½¢å¼
"""

import argparse
import json
import os
import sys
from pathlib import Path
from datetime import datetime

# Windowsç’°å¢ƒã§ã®UTF-8å‡ºåŠ›è¨­å®š
if sys.platform == 'win32':
    import codecs
    sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer, 'strict')
    sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer, 'strict')

# ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆè©¦è¡Œ
try:
    import numpy as np
    NUMPY_AVAILABLE = True
except ImportError:
    NUMPY_AVAILABLE = False
    print("âš ï¸  numpyãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“", file=sys.stderr)

try:
    import rasterio
    from rasterio.windows import Window
    RASTERIO_AVAILABLE = True
except ImportError:
    RASTERIO_AVAILABLE = False
    print("âš ï¸  rasterioãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“", file=sys.stderr)
    print("   pip install rasterio ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„", file=sys.stderr)

try:
    import h5py
    H5PY_AVAILABLE = True
except ImportError:
    H5PY_AVAILABLE = False
    print("âš ï¸  h5pyãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ (HDF5ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ç”¨)", file=sys.stderr)

try:
    import matplotlib
    matplotlib.use('Agg')  # GUIä¸è¦ã®ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰
    import matplotlib.pyplot as plt
    MATPLOTLIB_AVAILABLE = True
except ImportError:
    MATPLOTLIB_AVAILABLE = False
    print("âš ï¸  matplotlibãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ (å¯è¦–åŒ–ã‚ªãƒ—ã‚·ãƒ§ãƒ³ç”¨)", file=sys.stderr)


def read_geotiff_rasterio(file_path, lat, lon, buffer_km=5):
    """
    GeoTIFFãƒ•ã‚¡ã‚¤ãƒ«ã‚’rasterioã§èª­ã¿è¾¼ã¿

    Args:
        file_path: GeoTIFFãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        lat: ä¸­å¿ƒç·¯åº¦
        lon: ä¸­å¿ƒçµŒåº¦
        buffer_km: ãƒãƒƒãƒ•ã‚¡è·é›¢ï¼ˆkmï¼‰

    Returns:
        data, metadata, stats
    """
    if not RASTERIO_AVAILABLE:
        raise ImportError("rasterioãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")

    try:
        with rasterio.open(file_path) as src:
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—
            metadata = {
                "driver": src.driver,
                "dtype": str(src.dtypes[0]),
                "nodata": src.nodata,
                "width": src.width,
                "height": src.height,
                "count": src.count,
                "crs": str(src.crs),
                "bounds": src.bounds,
            }

            # åº§æ¨™å¤‰æ›ï¼ˆç·¯åº¦çµŒåº¦ â†’ ãƒ”ã‚¯ã‚»ãƒ«åº§æ¨™ï¼‰
            py, px = src.index(lon, lat)

            # ãƒãƒƒãƒ•ã‚¡è¨ˆç®—ï¼ˆãŠãŠã‚ˆã1km = 0.01åº¦ï¼‰
            buffer_pixels = int(buffer_km * 0.01 / abs(src.transform[0]))

            # ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦å®šç¾©
            window = Window(
                max(0, px - buffer_pixels),
                max(0, py - buffer_pixels),
                min(buffer_pixels * 2, src.width),
                min(buffer_pixels * 2, src.height)
            )

            # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
            data = src.read(1, window=window)

            # NoDataãƒžã‚¹ã‚¯é©ç”¨
            if src.nodata is not None:
                data = np.ma.masked_equal(data, src.nodata)

            # çµ±è¨ˆè¨ˆç®—
            stats = calculate_statistics(data)

            return data, metadata, stats

    except Exception as e:
        raise RuntimeError(f"GeoTIFFèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")


def read_hdf5_gcom_c(file_path, lat, lon, buffer_km=5, dataset_name="LST"):
    """
    GCOM-C/SGLI HDF5ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿

    Args:
        file_path: HDF5ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        lat: ä¸­å¿ƒç·¯åº¦
        lon: ä¸­å¿ƒçµŒåº¦
        buffer_km: ãƒãƒƒãƒ•ã‚¡è·é›¢ï¼ˆkmï¼‰
        dataset_name: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå (LST, NDVIç­‰)

    Returns:
        data, metadata, stats
    """
    if not H5PY_AVAILABLE:
        raise ImportError("h5pyãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")

    try:
        with h5py.File(file_path, 'r') as f:
            # ãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ ç¢ºèª
            print(f"\nðŸ“‚ HDF5ãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ :")
            print_hdf5_structure(f, max_depth=2)

            # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ¤œç´¢ï¼ˆä¸€èˆ¬çš„ãªãƒ‘ã‚¹ï¼‰
            possible_paths = [
                f'Image_data/{dataset_name}',
                f'Geophysical_data/{dataset_name}',
                dataset_name,
            ]

            data_path = None
            for path in possible_paths:
                if path in f:
                    data_path = path
                    break

            if not data_path:
                # ãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã®å ´åˆã¯ç”Ÿæˆ
                print("âš ï¸  å®Ÿãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¾ã™ã€‚")
                data = generate_mock_data(dataset_name, buffer_km)
                metadata = {
                    "file": str(file_path),
                    "dataset": dataset_name,
                    "source": "mock",
                    "shape": data.shape
                }
            else:
                # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
                dataset = f[data_path]
                data = dataset[:]

                metadata = {
                    "file": str(file_path),
                    "dataset": data_path,
                    "shape": dataset.shape,
                    "dtype": str(dataset.dtype),
                    "attrs": dict(dataset.attrs) if hasattr(dataset, 'attrs') else {}
                }

            # çµ±è¨ˆè¨ˆç®—
            stats = calculate_statistics(data)

            return data, metadata, stats

    except Exception as e:
        raise RuntimeError(f"HDF5èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")


def print_hdf5_structure(hdf_file, prefix="", max_depth=3, current_depth=0):
    """HDF5ãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ ã‚’è¡¨ç¤º"""
    if current_depth >= max_depth:
        return

    for key in hdf_file.keys():
        item = hdf_file[key]
        print(f"{prefix}â”œâ”€â”€ {key}")

        if isinstance(item, h5py.Group) and current_depth < max_depth - 1:
            print_hdf5_structure(item, prefix + "â”‚   ", max_depth, current_depth + 1)


def generate_mock_data(dataset_name, buffer_km):
    """ãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"""
    size = int(buffer_km * 20)  # é©å½“ãªã‚µã‚¤ã‚º

    if dataset_name == "LST":
        # åœ°è¡¨é¢æ¸©åº¦ï¼ˆKelvinï¼‰ã®ãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿
        mean_temp = 291.5  # ç´„18.35Â°C
        data = np.random.normal(mean_temp, 3.0, (size, size))
    elif dataset_name in ["NDVI", "VGI"]:
        # NDVIãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ï¼ˆ0ï½ž1ã®ç¯„å›²ï¼‰
        data = np.random.uniform(0.6, 0.85, (size, size))
    else:
        # æ±Žç”¨ãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿
        data = np.random.random((size, size))

    return data


def calculate_statistics(data):
    """
    çµ±è¨ˆå€¤ã‚’è¨ˆç®—

    Args:
        data: numpyé…åˆ—

    Returns:
        çµ±è¨ˆæƒ…å ±è¾žæ›¸
    """
    if not NUMPY_AVAILABLE:
        return {"error": "numpyæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«"}

    # ãƒžã‚¹ã‚¯é…åˆ—å¯¾å¿œ
    if isinstance(data, np.ma.MaskedArray):
        data_clean = data.compressed()
    else:
        data_clean = data.flatten()

    # æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿ãƒã‚§ãƒƒã‚¯
    data_clean = data_clean[~np.isnan(data_clean)]

    if len(data_clean) == 0:
        return {
            "valid_pixels": 0,
            "error": "æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“"
        }

    stats = {
        "valid_pixels": int(len(data_clean)),
        "mean": float(np.mean(data_clean)),
        "median": float(np.median(data_clean)),
        "std": float(np.std(data_clean)),
        "min": float(np.min(data_clean)),
        "max": float(np.max(data_clean)),
        "percentiles": {
            "25": float(np.percentile(data_clean, 25)),
            "50": float(np.percentile(data_clean, 50)),
            "75": float(np.percentile(data_clean, 75))
        }
    }

    return stats


def create_histogram(data, output_path, title="ãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒ", xlabel="å€¤"):
    """
    ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã‚’ç”Ÿæˆ

    Args:
        data: numpyé…åˆ—
        output_path: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        title: ã‚°ãƒ©ãƒ•ã‚¿ã‚¤ãƒˆãƒ«
        xlabel: Xè»¸ãƒ©ãƒ™ãƒ«
    """
    if not MATPLOTLIB_AVAILABLE:
        print("âš ï¸  matplotlibãŒåˆ©ç”¨ã§ããªã„ãŸã‚ã€ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ç”Ÿæˆã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™", file=sys.stderr)
        return None

    # ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
    if isinstance(data, np.ma.MaskedArray):
        data_clean = data.compressed()
    else:
        data_clean = data.flatten()

    data_clean = data_clean[~np.isnan(data_clean)]

    if len(data_clean) == 0:
        print("âš ï¸  æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒãªã„ãŸã‚ã€ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ç”Ÿæˆã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™", file=sys.stderr)
        return None

    # ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ä½œæˆ
    plt.figure(figsize=(10, 6))
    plt.hist(data_clean, bins=50, edgecolor='black', alpha=0.7)
    plt.title(title, fontsize=14, fontweight='bold')
    plt.xlabel(xlabel, fontsize=12)
    plt.ylabel('é »åº¦', fontsize=12)
    plt.grid(True, alpha=0.3)

    # çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º
    stats_text = f"å¹³å‡: {np.mean(data_clean):.2f}\næ¨™æº–åå·®: {np.std(data_clean):.2f}"
    plt.text(0.02, 0.98, stats_text,
             transform=plt.gca().transAxes,
             verticalalignment='top',
             bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

    plt.tight_layout()
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    plt.close()

    print(f"âœ“ ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ä¿å­˜: {output_path}")
    return output_path


def process_file(file_path, lat, lon, buffer_km, dataset_name, create_viz):
    """
    ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†

    Args:
        file_path: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        lat: ç·¯åº¦
        lon: çµŒåº¦
        buffer_km: ãƒãƒƒãƒ•ã‚¡è·é›¢
        dataset_name: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå
        create_viz: å¯è¦–åŒ–ã‚’ä½œæˆã™ã‚‹ã‹

    Returns:
        çµæžœè¾žæ›¸
    """
    file_path = Path(file_path)

    # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª
    if not file_path.exists():
        raise FileNotFoundError(f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}")

    print(f"\nðŸ“Š ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†: {file_path.name}")
    print(f"   åº§æ¨™: ({lat}, {lon})")
    print(f"   ãƒãƒƒãƒ•ã‚¡: {buffer_km}km")

    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—åˆ¤å®š
    suffix = file_path.suffix.lower()

    try:
        if suffix in ['.tif', '.tiff']:
            # GeoTIFFå‡¦ç†
            data, metadata, stats = read_geotiff_rasterio(file_path, lat, lon, buffer_km)

        elif suffix in ['.h5', '.hdf5']:
            # HDF5å‡¦ç†
            data, metadata, stats = read_hdf5_gcom_c(file_path, lat, lon, buffer_km, dataset_name)

        else:
            raise ValueError(f"æœªå¯¾å¿œã®ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼: {suffix}")

        # çµæžœä½œæˆ
        result = {
            "file": str(file_path),
            "processing_time": datetime.now().isoformat(),
            "location": {
                "latitude": lat,
                "longitude": lon,
                "buffer_km": buffer_km
            },
            "metadata": metadata,
            "statistics": stats
        }

        # å¯è¦–åŒ–ä½œæˆ
        if create_viz and MATPLOTLIB_AVAILABLE and NUMPY_AVAILABLE:
            viz_dir = file_path.parent.parent / "visualizations"
            viz_dir.mkdir(parents=True, exist_ok=True)

            hist_path = viz_dir / f"{file_path.stem}_histogram.png"
            create_histogram(data, hist_path,
                           title=f"{dataset_name} ãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒ - {file_path.stem}",
                           xlabel=dataset_name)

            result["visualization"] = str(hist_path)

        return result

    except Exception as e:
        return {
            "file": str(file_path),
            "error": str(e),
            "processing_time": datetime.now().isoformat()
        }


def main():
    parser = argparse.ArgumentParser(
        description="GeoTIFF/HDF5ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã—ã¦çµ±è¨ˆæƒ…å ±ã‚’æŠ½å‡º"
    )
    parser.add_argument("file", type=str, help="GeoTIFF/HDF5ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹")
    parser.add_argument("--lat", type=float, required=True, help="ä¸­å¿ƒç·¯åº¦")
    parser.add_argument("--lon", type=float, required=True, help="ä¸­å¿ƒçµŒåº¦")
    parser.add_argument("--buffer", type=float, default=5.0,
                       help="ãƒãƒƒãƒ•ã‚¡è·é›¢ï¼ˆkmã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 5ï¼‰")
    parser.add_argument("--dataset", type=str, default="LST",
                       help="ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåï¼ˆHDF5ç”¨ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: LSTï¼‰")
    parser.add_argument("--viz", action="store_true",
                       help="ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã‚’ç”Ÿæˆ")
    parser.add_argument("--output", type=str,
                       help="çµæžœJSONã®å‡ºåŠ›å…ˆï¼ˆæŒ‡å®šã—ãªã„å ´åˆã¯æ¨™æº–å‡ºåŠ›ï¼‰")

    args = parser.parse_args()

    print("\n" + "=" * 70)
    print("GeoTIFF/HDF5 ãƒ—ãƒ­ã‚»ãƒƒã‚µ")
    print("=" * 70)

    # ä¾å­˜ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒã‚§ãƒƒã‚¯
    if not NUMPY_AVAILABLE:
        print("\nâŒ ã‚¨ãƒ©ãƒ¼: numpyãŒå¿…è¦ã§ã™", file=sys.stderr)
        print("   pip install numpy ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„", file=sys.stderr)
        sys.exit(1)

    # ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†
    result = process_file(
        args.file,
        args.lat,
        args.lon,
        args.buffer,
        args.dataset,
        args.viz
    )

    # çµæžœå‡ºåŠ›
    if args.output:
        with open(args.output, 'w', encoding='utf-8') as f:
            json.dump(result, f, indent=2, ensure_ascii=False)
        print(f"\nâœ“ çµæžœä¿å­˜: {args.output}")
    else:
        print("\nðŸ“„ å‡¦ç†çµæžœ:")
        print(json.dumps(result, indent=2, ensure_ascii=False))

    print("\n" + "=" * 70)
    print("âœ“ å‡¦ç†å®Œäº†")
    print("=" * 70)


if __name__ == "__main__":
    main()
